{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from NozPiker_Funcs import main as NZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Path\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()),'data/build_data')\n",
    "MRC_PATH = os.path.join(DATA_DIR,'PROTEASOME_1PMA_3_proj.mrcs')\n",
    "Pkl_Path = os.path.join(DATA_DIR,'Train.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contents of MRC\n",
    "# Blank Dict\n",
    "Train = {}\n",
    "size = NZ.GetImageSet(MRC_PATH,'Proteasome',Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create training data\n",
    "def CreateTrainingData(store, size):\n",
    "    from numpy import array, where, zeros, min, max, resize, transpose\n",
    "    from tensorflow.image import resize_with_crop_or_pad\n",
    "    # Get Dict keys\n",
    "    class_names = array(sorted(store.keys()))\n",
    "    # Pre-allocate arrays\n",
    "    key = class_names[0]\n",
    "    length = len(store[key])\n",
    "    shape = (size,size)\n",
    "    train_images = zeros((length,shape[0],shape[1]))\n",
    "    train_labels = zeros(length)\n",
    "    # Load images and labels\n",
    "    for key in class_names:\n",
    "        loc = where(class_names == key)[0]\n",
    "        # Add images\n",
    "        if store[key][1].shape[1] < size:\n",
    "            for i in range(len(store[key])):\n",
    "                array = (store[key][i] - min(store[key][i]))/(max(store[key][i]) - min(store[key][i]))\n",
    "                array = resize(array,(array.shape[0],array.shape[1],1))\n",
    "                array = resize_with_crop_or_pad(array,size,size)\n",
    "                array = np.transpose(array,(2,0,1))\n",
    "                train_images[(loc*length)+i,:,:] = array\n",
    "                train_labels[(loc*length)+i] = loc\n",
    "    return train_images, train_labels, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label, class_names = CreateTrainingData(Train,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(500,500)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 948us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 914us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 926us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3eed15fb80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_image, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
